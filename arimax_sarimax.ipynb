{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc55a520-01bc-44da-ac02-787c662e6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6c46ae-4428-4173-b9c9-8ca52bb49993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>58.485714</td>\n",
       "      <td>58.928570</td>\n",
       "      <td>58.428570</td>\n",
       "      <td>58.747143</td>\n",
       "      <td>50.765709</td>\n",
       "      <td>75555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>58.571430</td>\n",
       "      <td>59.240002</td>\n",
       "      <td>58.468571</td>\n",
       "      <td>59.062859</td>\n",
       "      <td>51.038536</td>\n",
       "      <td>65005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>59.278572</td>\n",
       "      <td>59.792858</td>\n",
       "      <td>58.952858</td>\n",
       "      <td>59.718571</td>\n",
       "      <td>51.605175</td>\n",
       "      <td>67817400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>59.967144</td>\n",
       "      <td>60.392857</td>\n",
       "      <td>59.888573</td>\n",
       "      <td>60.342857</td>\n",
       "      <td>52.144630</td>\n",
       "      <td>79573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>60.785713</td>\n",
       "      <td>61.107143</td>\n",
       "      <td>60.192856</td>\n",
       "      <td>60.247143</td>\n",
       "      <td>52.061932</td>\n",
       "      <td>98506100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2012-01-03  58.485714  58.928570  58.428570  58.747143  50.765709  75555200\n",
       "1  2012-01-04  58.571430  59.240002  58.468571  59.062859  51.038536  65005500\n",
       "2  2012-01-05  59.278572  59.792858  58.952858  59.718571  51.605175  67817400\n",
       "3  2012-01-06  59.967144  60.392857  59.888573  60.342857  52.144630  79573200\n",
       "4  2012-01-09  60.785713  61.107143  60.192856  60.247143  52.061932  98506100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c41a591-9c9b-4ce5-9cfc-f2f162728b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------\n",
    "# Streamlit Page Config\n",
    "# ---------------------------------------\n",
    "st.set_page_config(page_title=\"SARIMAX & ARIMAX Forecast\", layout=\"wide\")\n",
    "st.title(\"ðŸ“ˆ Stock Forecasting: SARIMAX & ARIMAX Comparison\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1. Load Dataset\n",
    "# ---------------------------------------\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "    df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], errors='coerce', dayfirst=True)\n",
    "    df = df.dropna(subset=[df.columns[0]])\n",
    "    df = df.sort_values(by=df.columns[0])\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    df = df.asfreq(\"D\", method=\"pad\")\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "st.subheader(\"Dataset Preview\")\n",
    "st.write(df.head())\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2. User Inputs\n",
    "# ---------------------------------------\n",
    "st.subheader(\"Select Target Column\")\n",
    "target_column = st.selectbox(\"Target Column\", df.columns)\n",
    "\n",
    "st.subheader(\"Select Exogenous Variables (for ARIMAX)\")\n",
    "exog_columns = st.multiselect(\"Select Exogenous Columns\", \n",
    "                              [col for col in df.columns if col != target_column])\n",
    "\n",
    "st.subheader(\"Select Training Date Range\")\n",
    "start_date = st.date_input(\"Start Date\", value=df.index.min().date())\n",
    "end_date = st.date_input(\"End Date\", value=df.index.max().date())\n",
    "\n",
    "filtered_df = df.loc[str(start_date):str(end_date)]\n",
    "\n",
    "if len(filtered_df) < 20:\n",
    "    st.error(\"Please select at least 20 days of data.\")\n",
    "    st.stop()\n",
    "\n",
    "st.write(\"Filtered Data:\")\n",
    "st.write(filtered_df.head())\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3. SARIMAX Parameters\n",
    "# ---------------------------------------\n",
    "st.subheader(\"Define SARIMAX Parameters\")\n",
    "p = st.number_input(\"SARIMAX p\", min_value=0, value=1)\n",
    "d = st.number_input(\"SARIMAX d\", min_value=0, value=1)\n",
    "q = st.number_input(\"SARIMAX q\", min_value=0, value=1)\n",
    "P = st.number_input(\"SARIMAX P\", min_value=0, value=1)\n",
    "D = st.number_input(\"SARIMAX D\", min_value=0, value=1)\n",
    "Q = st.number_input(\"SARIMAX Q\", min_value=0, value=1)\n",
    "m = st.number_input(\"Seasonal Period (m)\", min_value=1, value=7)\n",
    "\n",
    "forecast_steps = st.number_input(\"Days to Forecast\", min_value=1, value=30)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4. Train Models & Forecast\n",
    "# ---------------------------------------\n",
    "st.subheader(\"Train and Compare Models\")\n",
    "\n",
    "if st.button(\"Train and Forecast\"):\n",
    "    y = filtered_df[target_column]\n",
    "    results = []\n",
    "\n",
    "    sarimax_fit = None\n",
    "    arimax_fit = None\n",
    "\n",
    "    # ---------- SARIMAX ----------\n",
    "    with st.spinner(\"Training SARIMAX...\"):\n",
    "        try:\n",
    "            sarimax_model = SARIMAX(\n",
    "                y,\n",
    "                order=(p, d, q),\n",
    "                seasonal_order=(P, D, Q, m),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            sarimax_fit = sarimax_model.fit()\n",
    "            sarimax_rmse = np.sqrt(mean_squared_error(y, sarimax_fit.fittedvalues))\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": \"SARIMAX\",\n",
    "                \"AIC\": sarimax_fit.aic,\n",
    "                \"BIC\": sarimax_fit.bic,\n",
    "                \"RMSE\": sarimax_rmse\n",
    "            })\n",
    "\n",
    "            st.success(f\"SARIMAX trained successfully! RMSE: {sarimax_rmse:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            st.warning(f\"SARIMAX failed: {e}\")\n",
    "\n",
    "    # ---------- ARIMAX ----------\n",
    "    if exog_columns:\n",
    "        with st.spinner(\"Training ARIMAX...\"):\n",
    "            exog_data = filtered_df[exog_columns]\n",
    "            try:\n",
    "                arimax_model = SARIMAX(\n",
    "                    y,\n",
    "                    order=(p, d, q),\n",
    "                    exog=exog_data,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False\n",
    "                )\n",
    "                arimax_fit = arimax_model.fit()\n",
    "                arimax_rmse = np.sqrt(mean_squared_error(y, arimax_fit.fittedvalues))\n",
    "\n",
    "                results.append({\n",
    "                    \"Model\": \"ARIMAX\",\n",
    "                    \"AIC\": arimax_fit.aic,\n",
    "                    \"BIC\": arimax_fit.bic,\n",
    "                    \"RMSE\": arimax_rmse\n",
    "                })\n",
    "\n",
    "                st.success(f\"ARIMAX trained successfully! RMSE: {arimax_rmse:.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                st.error(f\"ARIMAX failed: {e}\")\n",
    "    else:\n",
    "        st.info(\"No exogenous variables selected. ARIMAX skipped.\")\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Compare & Select Best Model\n",
    "    # ---------------------------------------\n",
    "    if results:\n",
    "\n",
    "        results_df = pd.DataFrame(results).sort_values(\"AIC\")\n",
    "\n",
    "        # CASE 1 â†’ ONLY ONE MODEL (skip comparison table)\n",
    "        if len(results_df) == 1:\n",
    "            only_model = results_df.iloc[0]\n",
    "\n",
    "            st.info(\"Only one model was trained â€” skipping model comparison.\")\n",
    "            st.write(f\"*Model:* {only_model['Model']}\")\n",
    "            st.write(f\"*AIC:* {only_model['AIC']:.4f}\")\n",
    "            st.write(f\"*BIC:* {only_model['BIC']:.4f}\")\n",
    "            st.write(f\"*RMSE:* {only_model['RMSE']:.4f}\")\n",
    "\n",
    "            best_model_name = only_model[\"Model\"]\n",
    "\n",
    "        # CASE 2 â†’ Multiple models\n",
    "        else:\n",
    "            st.write(\"### Model Comparison (sorted by AIC)\")\n",
    "            st.dataframe(results_df)\n",
    "\n",
    "            best_model_name = results_df.loc[results_df[\"AIC\"].idxmin(), \"Model\"]\n",
    "            st.success(f\"Best Model Selected: {best_model_name}\")\n",
    "\n",
    "        # ---------- SELECT MODEL FOR FORECAST ----------\n",
    "        if best_model_name == \"SARIMAX\":\n",
    "            forecast_model = sarimax_fit\n",
    "            exog_forecast = None\n",
    "\n",
    "        else:\n",
    "            forecast_model = arimax_fit\n",
    "            last_exog = exog_data.iloc[-1:]\n",
    "            exog_forecast = pd.concat([last_exog] * forecast_steps)\n",
    "            exog_forecast.index = pd.date_range(\n",
    "                filtered_df.index[-1] + pd.Timedelta(days=1),\n",
    "                periods=forecast_steps\n",
    "            )\n",
    "\n",
    "        # ---------- FORECAST ----------\n",
    "        forecast = forecast_model.get_forecast(steps=forecast_steps, exog=exog_forecast)\n",
    "        forecast_mean = forecast.predicted_mean\n",
    "        conf_int = forecast.conf_int()\n",
    "\n",
    "        future_dates = pd.date_range(\n",
    "            filtered_df.index[-1] + pd.Timedelta(days=1),\n",
    "            periods=forecast_steps\n",
    "        )\n",
    "\n",
    "        forecast_df = pd.DataFrame({\n",
    "            \"Date\": future_dates,\n",
    "            \"Prediction\": forecast_mean.values,\n",
    "            \"Lower\": conf_int.iloc[:, 0].values,\n",
    "            \"Upper\": conf_int.iloc[:, 1].values\n",
    "        }).set_index(\"Date\")\n",
    "\n",
    "        st.subheader(\"Forecast\")\n",
    "        st.write(forecast_df)\n",
    "\n",
    "        # ---------- PLOT ----------\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(filtered_df[target_column], label=\"Training Data\")\n",
    "        ax.plot(forecast_df[\"Prediction\"], label=f\"Forecast ({best_model_name})\", linestyle=\"--\")\n",
    "        ax.fill_between(forecast_df.index, forecast_df[\"Lower\"], forecast_df[\"Upper\"],\n",
    "                        color='orange', alpha=0.2)\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(target_column)\n",
    "        ax.set_title(f\"Forecast using {best_model_name}\")\n",
    "\n",
    "        st.pyplot(fig)\n",
    "\n",
    "    else:\n",
    "        st.error(\"No model could be trained. Please check your data or parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470ba9a5-2e37-465b-b53a-3e67f79a1333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "streamlit\n",
    "pandas\n",
    "numpy\n",
    "matplotlib\n",
    "statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfd7356d-af96-4cf7-85e1-6370199e3bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e07b005b-3654-4c12-ac65-8c1942d5776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[target_column].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2247a2b1-85c7-4c31-b1e9-8513084524e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[target_column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b047edb-31ea-4202-81ed-84f28d5b5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[target_column].isna().sum())  # should print 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89113c-39d7-4091-b351-9f6b834a2c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
